# Contexto del Proyecto: B煤squeda Sem谩ntica Local (RAG Embeddings)

## 1. Visi贸n General

Este proyecto implementa un servidor de embeddings local de alto rendimiento y bajo consumo de recursos, dise帽ado espec铆ficamente para potenciar un sistema RAG (Retrieval-Augmented Generation) con capacidades superiores en idioma espa帽ol. El objetivo es reemplazar soluciones sub贸ptimas (como Nomic v1.5) por una arquitectura alineada con el hardware disponible.

## 2. Estado Actual (17/01/2026)

- **Estado:**  Operativo / En Producci贸n Local
- **Progreso:** La infraestructura base (llama.cpp compilado con Vulkan) y el modelo optimizado est谩n desplegados y funcionando.
- **ltima Acci贸n:** Despliegue exitoso del servidor de inferencia con aceleraci贸n de GPU Iris Xe.

## 3. Arquitectura Implementada

### 3.1 Stack Tecnol贸gico

- **Motor de Inferencia:** `llama.cpp` (Compilaci贸n personalizada `b2ff3` o superior).
- **Backend de Aceleraci贸n:** Vulkan (para Intel Iris Xe Graphics).
- **Sistema Operativo:** CachyOS (Linux optimizado para latencia).
- **Hardware Objetivo:** ASUS Zenbook (Intel Core i7-1260P, 16GB LPDDR5).

### 3.2 Modelo de Embeddings

- **Modelo:** `snowflake-arctic-embed-m-v2.0` (GGUF).
- **Cuantizaci贸n:** `Q4_K_M` (~71 MB en disco, ~190 MB en RAM/VRAM).
- **Ventajas Clave:**
  - **Ventana de Contexto:** 8192 tokens (Crucial para documentos t茅cnicos largos).
  - **Multiling眉ismo:** Soporte nativo y superior para Espa帽ol (Benchmark MIRACL).
  - **Eficiencia:** 100% de descarga a GPU (Offload) en hardware de 16GB.

## 4. Configuraci贸n T茅cnica

### 4.1 Estrategia de Compilaci贸n

Se utiliz贸 una compilaci贸n espec铆fica para maximizar el uso de instrucciones nativas de Intel y la API Vulkan:

```bash
cmake -B build -DGGML_VULKAN=1 -DGGML_NATIVE=ON
cmake --build build --config Release
```

### 4.2 Par谩metros de Ejecuci贸n

El servidor se inicia con el script `start_embedding_server.sh` que aplica:

- `-ngl 99`: Fuerza la descarga de **todas** las capas a la GPU.
- `-c 8192`: Habilita el contexto completo del modelo.
- `-b 512`: Batch size optimizado para evitar saturaci贸n t茅rmica de la Iris Xe.
- `--embedding`: Activa el modo exclusivo de embeddings (endpoint `/embeddings`).

## 5. Scripts y Herramientas

Ubicaci贸n: `/home/peter/DEV/llama.cpp/`

| Archivo | Prop贸sito |
| :--- | :--- |
| `start_embedding_server.sh` | Lanza el servidor en puerto 8080. **Script principal de uso.** |
| `download_model.sh` | Descarga/Actualiza el modelo GGUF desde HuggingFace. |
| `find_model.py` | Utilidad Python para buscar modelos GGUF compatibles en HF. |
| `Optimizaci贸n de Embeddings...md` | Informe t茅cnico base que justifica la arquitectura. |

## 6. Pr贸ximos Pasos Pendientes

1. **Integraci贸n:** Conectar este endpoint (localhost:8080/v1/embeddings) con la base de datos vectorial (ej. ChromaDB, Qdrant) o la aplicaci贸n RAG.
2. **Pruebas de Carga:** Verificar latencia bajo estr茅s de ingesta de documentos.
3. **Evaluaci贸n de Calidad:** Comparar resultados de recuperaci贸n "banco" (entidad) vs "banco" (silla) en espa帽ol.
